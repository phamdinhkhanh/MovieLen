{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Representation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dataset used in this analysis is [MovieLens 1M](https://grouplens.org/datasets/movielens/1m/). These files contain 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000. There are 3 main parts in this datasets which is descripted as below:\n",
    "\n",
    "**RATINGS**: \n",
    "All ratings is contained in the file \"ratings.dat\" and have following format:\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings\n",
    "\n",
    "**USERS**:\n",
    "User information is in the file \"users.dat\" and format as below:\n",
    "UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "All demographic information is provided voluntarily by the users and is\n",
    "not checked for accuracy.  Only users who have provided some demographic\n",
    "information are included in this data set.\n",
    "\n",
    "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
    "- Age is chosen from the following ranges: 1:  \"Under 18\" ; 18:  \"18-24\"; 25:  \"25-34\"; 35:  \"35-44\"; 45:  \"45-49\"; 50:  \"50-55\"; 56:  \"56+\".\n",
    "- Occupation is chosen from the following choices: 0:  \"other\" or not specified;  1:  \"academic/educator\";  2:  \"artist\";  3:  \"clerical/admin\";  4:  \"college/grad student\";  5:  \"customer service\";  6:  \"doctor/health care\";  7:  \"executive/managerial\";  8:  \"farmer\";  9:  \"homemaker\"; 10:  \"K-12 student\"; 11:  \"lawyer\"; 12:  \"programmer\"; 13:  \"retired\"; 14:  \"sales/marketing\"; 15:  \"scientist\"; 16:  \"self-employed\"; 17:  \"technician/engineer\"; 18:  \"tradesman/craftsman\"; 19:  \"unemployed\"; 20:  \"writer\".\n",
    "\n",
    "**MOVIES**:\n",
    "Movie information is in the file \"movies.dat\" its format is:\n",
    "MovieID::Title::Genres\n",
    "\n",
    "- Titles are identical to titles provided by the IMDB (including\n",
    "year of release)\n",
    "- Genres are pipe-separated and are selected from the following genres: Action; Adventure; Animation; Children's; Comedy; Crime; Documentary; Drama; Fantasy; Film-Noir; Horror; Musical; Mystery; Romance; Sci-Fi; Thriller; War; Western\n",
    "\n",
    "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
    "entries and/or test entries\n",
    "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n",
    "\n",
    "Our target is building a algorithms to assign the best adapted movie to each user. The variate is forecasted in model is customer rating on each movie. We will split data into train and test dataset. The model is builded in train dataset and test dataset is used to judge difference between rating truth and rating forecast. Metric we use to minimize is root mean squared error ([RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) for rating). About approaches, there 2 natural ways for this problem are `Content-Based System` and `Collaborative Filtering` we will mention as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Content-Based System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Content-Based System is suggestion method which based on characteristics of items to recommend for user. Basically, we build a regression or classification for each user using items profile of items as input. The items profile is a set information of each item, for example: movie genre, production year, director,.... This model will used to forecast the remaining rating which this user have not rated yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assume that we have totally N users and M items. We denote utility matrix is $\\mathbf{Y}$ (shape `MxN`). The element $y_{mn}$ (row `m'th` and column `n'th`) of $\\mathbf{Y}$ matrix represent to how much interesting of user n on item m throught rating point. Rating point is high meaning that user enjoy the item and in contrast. Beside, we should take attention that there are many elements in Y matrix are empty and need to forecast. Thus, we generate $\\mathbf{R}$ is `rated or not` matrix demonstrating one user have rated to one item yet. In detail, $r_{ij} = 1$ in case item `i'th` is rated by user `j'th` and opposite is 0.\n",
    "\n",
    "**Linear model:**\n",
    "\n",
    "We can choose logistic model for binary classification but this analysis is multiple classification. So linear model is more reasonable. Let's say we can find one linear model for each user with $w_{i}$ is parameter vector and $b_{i}$ is bias for each model. Thus, the rating estimation of one user to one item can be shown as:\n",
    "\n",
    "$$y_{mn} = \\mathbf{x}_m\\mathbf{w}_m + b_n$$\n",
    "\n",
    "($\\mathbf{x}_m$ is row vector and $\\mathbf{w}_m$ is column vector)\n",
    "\n",
    "**Loss function**\n",
    "\n",
    "We consider to given user `n'th`, if suppose training set is whole elements are filled. The loss function is constructed with regularization norm 2 of parameters matrix (Ridge Regression) as below (norm 2 added to avoid overfiting and over high of $w$).\n",
    "\n",
    "$$\\mathcal{L}_n = \\frac{1}{2} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m \\mathbf{w}_n + b_n - y_{mn})^2 + \\frac{\\lambda}{2} ||\\mathbf{w}_n||_2^2$$\n",
    "\n",
    "($m~: r_{mn} = 1$ imply that only rated element is collected and $(\\mathbf{x}_m \\mathbf{w}_n + b_n - y_{mn})$ is error between actual and forecast rating values)\n",
    "\n",
    "In practical, to avoid loss function is too big what is highly happen in this case when there are million and million items. We usually take average of error. \n",
    "\n",
    "$$\\mathcal{L}_n = \\frac{1}{2s_{n}} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m \\mathbf{w}_n + b_n - y_{mn})^2 + \\frac{\\lambda}{2s_{n}} ||\\mathbf{w}_n||_2^2$$\n",
    "\n",
    "With $s_n$ is number of items what user `n'th` rated or total sum of column `n'th` in matrix $\\mathbf{R}$.\n",
    "$$s_n = \\sum_{m=1}^{M} r_{mn}$$\n",
    "\n",
    "Because of loss function only depend on items rated. Thus, we only need to extract sub vector $\\hat{\\mathbf{y_n}}$ of $\\mathbf{y}$ what is rated. Simultaneously, extract $\\hat{\\mathbf{X_n}}$ is sub matrix of feature matrix (generated from items profile) $\\mathbf{X}$. Now, the loss function as below:\n",
    "\n",
    "$$\\mathcal{L}_n = \\frac{1}{2s_n} ||\\hat{\\mathbf{X}}_n\\mathbf{w}_n + b_n \\mathbf{e}_n- \\hat{\\mathbf{y}}_n||_2^2 + \\frac{\\lambda}{2s_n} ||\\mathbf{w}_n||_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Construct Alogrithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At the first, we need to divide model into train and test dataset according to proportion 80:20. Model will build model in train dataset and loss function used to judge effectiveness in test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user:  6040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#reading the user file\n",
    "u_cols =  ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', names=u_cols,\n",
    " encoding='latin-1', engine='python')\n",
    "n_users = users.shape[0]\n",
    "print('Number of user: ', n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user:  1000209\n"
     ]
    }
   ],
   "source": [
    "#reading the rating file\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', names=r_cols,\n",
    " encoding='latin-1', engine='python')\n",
    "n_ratings = ratings.shape[0]\n",
    "print('Number of user: ', n_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Construct feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Constructing feature matrix is one of the best important in Content-Based System. The feature matrix will be builded on items profile. So firstly, we need to load whole items profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 3883\n"
     ]
    }
   ],
   "source": [
    "#Reading items file:\n",
    "i_cols = ['movie_id', 'movie_year', 'genre']\n",
    "items = pd.read_csv('ml-1m/movies.dat', sep='::',  names = i_cols,\n",
    " encoding='latin-1', engine = 'python')\n",
    "\n",
    "n_items = items.shape[0]\n",
    "print ('Number of items:', n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                          movie_year                         genre\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data to gain meaningful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                          movie_year                         genre  \\\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance   \n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
       "4         5  Father of the Bride Part II (1995)                        Comedy   \n",
       "\n",
       "                    movie_title  year  Action  Adventure  Animation  \\\n",
       "0                    Toy Story   1995     0.0        0.0        1.0   \n",
       "1                      Jumanji   1995     0.0        1.0        0.0   \n",
       "2             Grumpier Old Men   1995     0.0        0.0        0.0   \n",
       "3            Waiting to Exhale   1995     0.0        0.0        0.0   \n",
       "4  Father of the Bride Part II   1995     0.0        0.0        0.0   \n",
       "\n",
       "   Children's  Comedy   ...     Fantasy  Film-Noir  Horror  Musical  Mystery  \\\n",
       "0         1.0     1.0   ...         0.0        0.0     0.0      0.0      0.0   \n",
       "1         1.0     0.0   ...         1.0        0.0     0.0      0.0      0.0   \n",
       "2         0.0     1.0   ...         0.0        0.0     0.0      0.0      0.0   \n",
       "3         0.0     1.0   ...         0.0        0.0     0.0      0.0      0.0   \n",
       "4         0.0     1.0   ...         0.0        0.0     0.0      0.0      0.0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0      0.0     0.0       0.0  0.0      0.0  \n",
       "1      0.0     0.0       0.0  0.0      0.0  \n",
       "2      1.0     0.0       0.0  0.0      0.0  \n",
       "3      0.0     0.0       0.0  0.0      0.0  \n",
       "4      0.0     0.0       0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "#Take the production year\n",
    "movie_year = items['movie_year']\n",
    "year = movie_year.apply(lambda x: pd.Series(re.findall(\"\\d+\",x)))[0]\n",
    "year = pd.to_numeric(year)\n",
    "year.name = 'year'\n",
    "\n",
    "#Take the movie_title\n",
    "movie_title = movie_year.apply(lambda x: pd.Series(re.sub(\"\\(\\d+\\)\",\"\",x)))[0]\n",
    "movie_title.name = 'movie_title'\n",
    "\n",
    "#Take the genre what movie belong to\n",
    "genre = items['genre']\n",
    "genre = genre.apply(lambda x: pd.Series(x.split('|')))\n",
    "freq_genre = genre.apply(pd.value_counts, axis = 1)\n",
    "freq_genre[freq_genre.isna()] = 0\n",
    "\n",
    "#Merge movie_title, production year, genre in to items\n",
    "items = items.join(movie_title).join(year).join(freq_genre)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because we are based on `genre` and `production year` to build profiles. So, we only forcus on 19 last columns and create features matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1995, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [1995, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n",
       "       [1995, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [2000, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [2000, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [2000, 0.0, 0.0, ..., 1.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0 = items.values\n",
    "X = X0[:, -19:]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can see that `production year` is too big. If we regression on the dataset what exist one feature is extremely bigger than other features then the estimation tendanly focus on this big feature and reduce explaination of the others. Thus we should rescale feature according to formula to make its range in $[0,1]$:\n",
    "$$x’ = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2215801755750639, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.2215801755750639, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.2215801755750639, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [0.22213579286587398, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.22213579286587398, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.22213579286587398, 0.0, 0.0, ..., 1.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "#suppress warning from old version\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scale_year = min_max_scaler.fit_transform(X[:,0])\n",
    "X[:,0] = scale_year\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we will build feature vector for each item based on feature matrix. What we generate at final is [TF-IDF](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html). This article will don't deeply dig into explaination of TF-IDF. In general, TF-IDF is implemented from word processing, it define how much effectiveness of one Movie to rating result based on its frequency. It is reasonable because one Movie are more frequently rated then it is increasingly well known and rating also tentatively higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03513442, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03066335, 0.        , 0.49957847, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0584175 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.11725149, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11725149, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0617305 , 0.        , 0.        , ..., 0.85018788, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
    "tfidf = transformer.fit_transform(X.tolist()).toarray()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After this step, each row of `tfidf` is a feature vector of each movie. Next we need to find the movie what user rated and its rating through `get_items_rated_by_user()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_items_rated_by_user(rate_matrix, user_id):\n",
    "    \"\"\"\n",
    "    in each line of rate_matrix, we have infor: user_id, item_id, rating (scores), time_stamp\n",
    "    we care about the first three values\n",
    "    return (item_ids, scores) rated by user user_id\n",
    "    \"\"\"\n",
    "    y = rate_matrix[:,0] # all users\n",
    "    # item indices rated by user_id\n",
    "    ids = np.where(y == user_id)[0] \n",
    "    item_ids = rate_matrix[ids, 1]\n",
    "    scores = rate_matrix[ids, 2]\n",
    "    return (item_ids, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we have already loaded all data include ratings, users and items profile. Next, We need to split data into train and test dataset according to proportion 80:20 (we also can choose other proportion such as 70:30, 50:50, ...). This is very simple by using `train_test_split` from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(123)\n",
    "X_train, X_test = train_test_split(ratings, test_size=0.2)\n",
    "rate_train = X_train.values\n",
    "rate_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Regression for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, with each user we need to make a Ridge Regression. Whole parameters and bias corresponding to each user are saved in parameter matrix $\\mathbf{W}$ and vector bias $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "\n",
    "d = tfidf.shape[1] # data dimension\n",
    "W = np.zeros((d, n_users))\n",
    "b = np.zeros((1, n_users))\n",
    "\n",
    "for n in range(n_users):    \n",
    "    items_of_n, scores = get_items_rated_by_user(rate_train, n+1) #plus 1 into user because range(n_users) start from 0\n",
    "    clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
    "    ids = [i for i,val in enumerate(items['movie_id']) if val in items_of_n]\n",
    "    Xhat = tfidf[ids, :]\n",
    "    \n",
    "    clf.fit(Xhat, scores) \n",
    "    W[:, n] = clf.coef_\n",
    "    b[0, n] = clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can easy to know that each column of $\\mathbf{W}$ is parameter vector corresponding with one user and each element in this column are parameter of one kind of `production year` and `genre`. Vector $b$ is bias of this linear model. After generating $\\mathbf{W}$ and $b$, the forecasted rating matrix $\\hat{\\mathbf{Y}}$ is calculating as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Yhat = tfidf.dot(W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04217507, -0.68300184, -0.19864851, ..., -0.58142549,\n",
       "        0.43412803,  0.32666803])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can forecast any users we want. For example, all forecast ratings of `user_id` = 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated movies ids : [31, 114, 148, 206, 257, 289, 335, 340, 360, 431, 539, 582, 584, 590, 755, 819, 912, 959, 1009, 1019, 1045, 1063, 1109, 1119, 1178, 1185, 1197, 1205, 1220, 1223, 1236, 1239, 1245, 1251, 1271, 1272, 1274, 1336, 1386, 1533, 1543, 1607, 1656, 1937, 1940, 1952, 1964, 1972, 2008, 2012, 2031, 2046, 2069, 2105, 2124, 2222, 2247, 2255, 2267, 2306, 2327, 2548, 2559, 2588, 2624, 2647, 2726, 2789, 2965, 2997, 3039, 3106, 3129, 3227, 3339, 3370, 3378, 3382, 3599, 3602, 3619, 3632]\n",
      "True ratings     : [5 4 5 5 4 3 5 4 4 4 5 4 3 3 5 4 5 5 5 4 3 2 3 5 4 3 4 5 5 4 5 3 5 5 5 5 3\n",
      " 5 4 5 5 4 5 4 5 4 3 5 4 5 5 3 3 3 3 4 3 5 5 4 5 4 5 4 3 3 4 5 5 5 5 4 4 5\n",
      " 5 5 4 4 4 3 2 5]\n",
      "Predicted ratings: [2.59 2.5  2.85 3.41 3.49 3.34 3.11 3.41 1.26 2.66 3.14 2.3  1.29 1.26\n",
      " 3.14 3.41 1.95 3.3  1.26 1.26 3.04 3.41 3.4  3.4  3.08 2.85 3.11 1.36\n",
      " 2.95 3.14 3.56 3.12 3.11 3.31 3.41 3.4  3.56 3.04 3.11 2.95 2.59 2.72\n",
      " 3.31 3.24 2.81 3.52 0.95 2.63 2.48 1.34 3.77 3.41 1.95 3.99 3.92 3.04\n",
      " 3.04 3.14 3.31 3.41 3.11 3.58 3.49 2.92 2.5  3.65 3.4  3.14 0.95 3.69\n",
      " 2.98 2.76 3.31 3.31 3.31 3.32 3.3  3.14 3.04 4.21 3.4  2.53]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "np.set_printoptions(precision=2) # 2 digits after . \n",
    "items_of_n, scores = get_items_rated_by_user(rate_test, n)\n",
    "ids = [i for i,val in enumerate(items['movie_id']) if val in items_of_n]\n",
    "Yhat[n, ids]\n",
    "print('Rated movies ids :', ids )\n",
    "print('True ratings     :', scores)\n",
    "print('Predicted ratings:', Yhat[ids, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To evaluate model we will use Root Mean Squared Error [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) for rating. Error is equal to deviation between `true rating` and `predicted rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for test    : 1.4634875893734853\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "def evaluate(Yhat, rates, W, b):\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for n in range(n_users):\n",
    "        items_of_n, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        ids = [i for i,val in enumerate(items['movie_id']) if val in items_of_n]\n",
    "        scores_pred = Yhat[ids, n]\n",
    "        e = scores_truth - scores_pred \n",
    "        se += (e*e).sum(axis = 0)\n",
    "        cnt += e.size \n",
    "    return sqrt(se/cnt)\n",
    "\n",
    "print ('RMSE for test    :', evaluate(Yhat, rate_test, W, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because of train and test dataset are change in each time we run model so `RMSE` you running could be different from this article result. To fixed results you just need \n",
    "\n",
    "`import random` \n",
    "\n",
    "`random.seed(any_number)`\n",
    "\n",
    "Error is 1.46 rating is a weak result in this problem. We should check a new method to see if the `RMSE` can be reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we known, Content-Based System forecast rating only use information of each item, which shown in feature matrix without using any user information. In constrast with Content-Based System, Collaborative-Filtering forecast the rating of one user for one item by using the rating of other users who are similar watching enjoyment. The similarity can be defined on the rating for the items. For example, we known that A,B like `Bed of Roses` (Romantic genre) and both of them rate for this movie 5 rate point and we also known A like `Honeymoon in Vegas` so we can suspect that likely B also like this movie. We will figure out the foundation of this alogrithm when response two question:\n",
    "\n",
    "* How do we define the similarity between two different users?\n",
    "* When we known similarity, how could we forecast interesting level of one user into one item?\n",
    "\n",
    "Moreover, there are two approaches for Collaborative-Filtering. The first, defining interesting level of one user on one item based on similar users, which called as `User-User collaborative filtering`. The second, based on the similar items with the high rating items to suppose them for user, which called as `Item-item collaborative filtering`. We will go through both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 User-user Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Similarity function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The best prior importance we should do is defining the similarity between two users. It only is infered from Utility Matrix $\\mathbf{Y}$ and we measure similarity on the columns of this matrix. \n",
    "\n",
    "<br/>\n",
    "<img src=\".\\utility.png\" alt=\"Utility Matrix\" width=\"200px\"/>\n",
    "<p align='center' style=\"text-align:center\">Picture1: Utility Matrix</p>\n",
    "<br/>\n",
    "\n",
    "We have example about utility matrix with each row is the ratings of each item from all users and each column is the whole ratings of each user. The grey with question mark represent to movie have not rated yet. At the first sight we figure out that $u_0$ is more similar to $u_1$ than $u_2, u_3, u_4, u_5, u_6$. One similarity function is conservative must sastify:\n",
    "$$\\text{sim}(u_0, u_1) > \\text{sim}(u_0, u_i), ~\\forall i > 1.$$\n",
    "In natural way, the function we chose is correlation. But one user only fill a small part of items set. This make our matrix is missing a lot and the correlation don't response exactly relationship between two user behavior. How do we deal with that? simply, we need to fill in matrix in the missing points. But what value should be filled in are most reasonable? Let's analysis in three scenarios:\n",
    "\n",
    "* Fill up the smallest rating, it mean 0: This way makes sense with severe users who tend to rating low point but with easy users it aren't judically. Actually, we will get bias with this group users.\n",
    "* Fill up the biggest rating, it mean 5: completely same with above. We aren't equal with severe group users.\n",
    "* The final, we fill up with mean: It is most conservative because we don't high rate with servere group users and also low rate with easy group users.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\".\\user_cf.png\" alt=\"Process of User-User Collaborative Filtering\"/>\n",
    "<p align='center' style=\"text-align:center\">Picture2: Process of User-User Collaborative Filtering</p>\n",
    "\n",
    "**Standardize data**\n",
    "\n",
    "Before we fill up Utility Matrix, we see that each user will have different mean of rating. The severe users maybe lower rating's mean than the easy users while our model don't care about what kind of user belong to. Hence, we need to standardize data to make servere users and easy users are equal. The simplest way is make their expectation rating become 0. This also benefit to storage when almost values in Utility Matrix are missing. After standardizing data, the means are 0 and we store Utility Matrix with almost 0 values. `Sparse Matrix` are useful to be used in this case (only store value different 0 and its position).\n",
    "\n",
    "**Cosine Similarity**\n",
    "\n",
    "Correlation also called as Cosine Similarity because its formula is similar with $cos$ between two vector $u_1, u_2$ and shown as below:\n",
    "$$\\text{cosine_similarity}(\\mathbf{u}_1, \\mathbf{u}_2) =\\text{cos}(\\mathbf{u}_1, \\mathbf{u}_2) \n",
    "=  \\frac{\\mathbf{u}_1^T\\mathbf{u}_2}{ ||\\mathbf{u}_1||_2.||\\mathbf{u}_2||_2}~~~~ (1)$$\n",
    "\n",
    "And very simple we all known:\n",
    "\n",
    "* consine similarity is between $[-1,1]$\n",
    "* when it is near 1, the similarity between two users are more high.\n",
    "* when it is near -1, the similarity between two users are in contrast.\n",
    "* when it is near 0, two users do not have much relationship. In other ways, they are not similar.\n",
    "\n",
    "**Rating prediction**\n",
    "\n",
    "After finding $K$ users are most similar, we need to estimate the rating of one item based on what $K$ users rated. The predicted rating usually calculate from weighted average of the standardized ratings. Each weighted is consine similarity with user we are forecasting to. For example the rating of user $u$ for $i$ is estimated:\n",
    "\n",
    "$$\\hat{y}_{i, u} = \\frac{\\sum_{u_j \\in \\mathcal{N}(u, i)} \\bar{y}_{i, u_j} \\text{sim}(u, u_j)}{\\sum_{u_j \\in \\mathcal{N}(u, i)} |\\text{sim}(u, u_j)|} ~~~~ (2)$$\n",
    "\n",
    "in which, $\\mathcal{N}(u,i)$ is group of $K$ most similar user with u who have **already rated** i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Items-items Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Items-items Collaborative Filtering absolutely similar with Users-users Collaborative Filtering about processing. What we should do for it when we have already built the processing code for Users-users Collaborative Filtering is transpose Utility Matrix $\\mathbf{Y}$. But it is in term of processing. Actually Items-items Collaborative Filtering is different meaning of User-user Collaborative Filtering at below sides:\n",
    "\n",
    "* We forecus on finding the items are similar with the highest rated items of one user to suggest him. Meanwhile User-user Collaborative Filtering based on similarity between the user pairs to forecast rating.\n",
    "\n",
    "* Actually, number of users is usually higher than items. Thus similarity matrix is small dimension than User-user Collaborative Filtering. It support to calculation alot in the following processes.\n",
    "\n",
    "In this article we will build function for both of this two methods through declare argument which decides if we transpose $\\mathbf{Y}$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 Construct alogrithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We build alogrithm following the way we describe above. To compare result with Content-Based Recommendation alogrithm, we use the same `rate_train` and `rate_test` with before model in chapter **2.2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of rate_train:  (800167, 4)\n",
      "Dimension of rate_test:  (200042, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of rate_train: \", rate_train.shape)\n",
    "print(\"Dimension of rate_test: \", rate_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To be more neat and easy to implement, we will initalize class CF for this alogrithms. All function for predicting, recommending or checking error are combined in this class. To create a complete class `CF`, you have to firstly run below code without totally understanding about its meaning. I will explain to each function in code in following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class CF(object):\n",
    "    #init function \n",
    "    def __init__(self, Y_data, K, dist_func = cosine_similarity, uuCF = 1):\n",
    "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
    "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]] #if item-item CF then only change column 1 to 0\n",
    "        self.K = K # number of neighbor points\n",
    "        self.dist_func = dist_func\n",
    "        self.Ybar_data = None\n",
    "        self.Ybar = None\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "        #create vector store mean rating of the movies what user rated.\n",
    "        self.mu = None\n",
    "        \n",
    "    def normalize_Y(self):\n",
    "        #take all users is first column of Y_data\n",
    "        all_users = self.Y_data[:, 0]\n",
    "        self.Ybar_data = self.Y_data.copy()\n",
    "        #take users unique list\n",
    "        users_list = np.unique(self.Y_data[:, 0])\n",
    "        #take dimension of users and items in sparse matrix. Because index start from 0 so we need to plus 1.\n",
    "        self.n_users = int(max(self.Y_data[:,0])+1)\n",
    "        self.n_items = int(max(self.Y_data[:,1])+1)\n",
    "        #create vector which store mean ratings of user u.\n",
    "        self.mu = np.zeros(self.n_users)\n",
    "        for u in users_list:\n",
    "            #find all rating ids which user = u rated\n",
    "            ids = np.where(all_users == u)\n",
    "            ratings_of_u = self.Y_data[ids, 2]\n",
    "            #take mean of rating\n",
    "            m = np.mean(ratings_of_u)\n",
    "            self.mu[u] = m\n",
    "            if np.isnan(m):\n",
    "                m = 0 #to avoid empty array and nan value\n",
    "            #standardize data\n",
    "            self.Ybar_data[ids, 2] = ratings_of_u - m\n",
    "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
    "                    (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
    "        self.Ybar = self.Ybar.tocsr()\n",
    "    \n",
    "    def similarity(self):   \n",
    "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.normalize_Y()\n",
    "        self.similarity()\n",
    "        \n",
    "    def __pred(self, u, i, normalized = 1):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        # Step 1: find all users who rated i\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)  \n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        # Step 2: find similarity btw the current user and others \n",
    "        # who already rated i\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        # Step 3: find the k most similarity users\n",
    "        a = np.argsort(sim)[-self.K:] \n",
    "        # and the corresponding similarity levels\n",
    "        nearest_s = sim[a]\n",
    "        # How did each of 'near' users rated item i\n",
    "        r = self.Ybar[i, users_rated_i[a]]\n",
    "        if normalized:\n",
    "            # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
    "            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
    "\n",
    "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]\n",
    "\n",
    "    def pred(self, u, i, normalized = 1):\n",
    "        if self.uuCF:\n",
    "            return self.__pred(u, i, normalized)\n",
    "        return self.__pred(i, u, normalized)\n",
    "    \n",
    "    def recommend(self, u, normalized = 1):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u. (uuCF =1)\n",
    "        or all users who might have interest on item u (uuCF = 0)\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which \n",
    "        have not been rated by u yet. \n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist() \n",
    "        #take users unique list\n",
    "        items_list = np.unique(self.Y_data[:, 1])\n",
    "        recommended_items = []\n",
    "\n",
    "        for i in items_list:\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.pred(u, i, self.uuCF)\n",
    "                if rating > 0: \n",
    "                    recommended_items.append([i, rating])\n",
    "        \n",
    "        if len(recommended_items) == 0: return []\n",
    "        recommended_items = np.array(recommended_items, dtype = 'f')\n",
    "        a = np.argsort(recommended_items[:,1])[::-1]\n",
    "        recommended_items = recommended_items[a, 0].astype(int).tolist()\n",
    "        return recommended_items\n",
    "\n",
    "    def print_recommendation(self, top, u):\n",
    "        \"\"\"\n",
    "        print all items which should be recommended for each user \n",
    "        \"\"\"\n",
    "        print ('Recommendation: ')\n",
    "        recommended_items = self.recommend(u)[:top]\n",
    "        if self.uuCF:\n",
    "            print ('Top ', top, ' recommend item(s):', recommended_items, 'to user', u)\n",
    "        else: \n",
    "            print ('Top ', top, ' recommend item', u, 'to user(s) : ', recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Actually class CF include three part: **initialize, fit and recommend**.\n",
    "\n",
    "**Initialize class CF**\n",
    "\n",
    "Initialize a CF class enable to us use every its functions (in programing we also call methods) and arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class CF(object):\n",
    "    #init function \n",
    "    def __init__(self, Y_data, K, dist_func = cosine_similarity, uuCF = 1):\n",
    "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
    "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]] #if item-item CF then only change column 1 to 0\n",
    "        self.K = K # number of neighbor points\n",
    "        self.dist_func = dist_func\n",
    "        self.Ybar_data = None\n",
    "        self.Ybar = None\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "        #create vector store mean rating of the movies what user rated.\n",
    "        self.mu = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Fit model**\n",
    "\n",
    "Fit model include two part are normalize Utility Matrix and calculate Similarity Matrix. In normalize Utility Matrix step, we transform $\\mathbf{Y}$ so each user rating are subtracted to its mean of the rating values which user rated. The Utility Matrix should be stored as [sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) to save the memory and calculation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize_Y(self):\n",
    "    #take all users is first column of Y_data\n",
    "    all_users = self.Y_data[:, 0]\n",
    "    self.Ybar_data = self.Y_data.copy()\n",
    "    #take users unique list\n",
    "    users_list = np.unique(self.Y_data[:, 0])\n",
    "    #take dimension of users and items in sparse matrix. Because index start from 0 so we need to plus 1.\n",
    "    self.n_users = int(max(self.Y_data[:,0])+1)\n",
    "    self.n_items = int(max(self.Y_data[:,1])+1)\n",
    "    #create vector which store mean ratings of user u.\n",
    "    self.mu = np.zeros(self.n_users)\n",
    "    for u in users_list:\n",
    "        #find all rating ids which user = u rated\n",
    "        ids = np.where(all_users == u)\n",
    "        ratings_of_u = self.Y_data[ids, 2]\n",
    "        #take mean of rating\n",
    "        m = np.mean(ratings_of_u)\n",
    "        self.mu[u] = m\n",
    "        if np.isnan(m):\n",
    "            m = 0 #to avoid empty array and nan value\n",
    "        #standardize data\n",
    "        self.Ybar_data[ids, 2] = ratings_of_u - m\n",
    "    self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
    "                (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
    "    self.Ybar = self.Ybar.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, each Ybar's column is the whole ratings of each user and each row is the whole ratings of each movie (rating are standardized). We easy to calculate Similarity matrix as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def similarity(self):   \n",
    "    self.S = self.dist_func(self.Ybar.T, self.Ybar.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create function fit() to activate normalize_Y() and similarity() each time we run model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fit(self):\n",
    "    self.normalize_Y()\n",
    "    self.similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Recommend**\n",
    "\n",
    "Create prediction function rating values for each user. This function predict rating of user u for item i (standardized) based on K most similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def __pred(self, u, i, normalized = 1):\n",
    "    \"\"\" \n",
    "    predict the rating of user u for item i (normalized)\n",
    "    if you need the un\n",
    "    \"\"\"\n",
    "    # Step 1: find all users who rated i\n",
    "    ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)  \n",
    "    users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "    # Step 2: find similarity btw the current user and others \n",
    "    # who already rated i\n",
    "    sim = self.S[u, users_rated_i]\n",
    "    # Step 3: find the k most similarity users\n",
    "    a = np.argsort(sim)[-self.K:] \n",
    "    # and the corresponding similarity levels\n",
    "    nearest_s = sim[a]\n",
    "    # How did each of 'near' users rated item i\n",
    "    r = self.Ybar[i, users_rated_i[a]]\n",
    "    if normalized:\n",
    "        # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
    "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
    "\n",
    "    return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]\n",
    "    \n",
    "def pred(self, u, i, normalized = 1):\n",
    "    if self.uuCF:\n",
    "        return self.__pred(u, i, normalized)\n",
    "    return self.__pred(i, u, normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With each user, we will use `pred()` function to forecast its normalized ratings on the movie user have not seen yet (we should note that ratings have been normalized). We filter all forecast normalized ratings > 0 to recommend customer. The priority based on forecast normalized ratings are big or small. `recommend()` function to find the movie and `print_recommendation()` to print out recommendation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def recommend(self, u, normalized = 1):\n",
    "    \"\"\"\n",
    "    Determine all items should be recommended for user u. (uuCF =1)\n",
    "    or all users who might have interest on item u (uuCF = 0)\n",
    "    The decision is made based on all i such that:\n",
    "    self.pred(u, i) > 0. Suppose we are considering items which \n",
    "    have not been rated by u yet. \n",
    "    \"\"\"\n",
    "    ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "    items_rated_by_u = self.Y_data[ids, 1].tolist() \n",
    "    #take users unique list\n",
    "    items_list = np.unique(self.Y_data[:, 1])\n",
    "    recommended_items = []\n",
    "    \n",
    "    for i in items_list:\n",
    "        if i not in items_rated_by_u:\n",
    "            rating = self.pred(u, i, self.uuCF)\n",
    "            if rating > 0: \n",
    "                recommended_items.append([i, rating])\n",
    "                \n",
    "    if len(recommended_items) == 0: return []\n",
    "    recommended_items = np.array(recommended_items, dtype = 'f')\n",
    "    a = np.argsort(recommended_items[:,1])[::-1]\n",
    "    recommended_items = recommended_items[a, 0].astype(int).tolist()\n",
    "    return recommended_items\n",
    "\n",
    "def print_recommendation(self, top, u):\n",
    "    \"\"\"\n",
    "    print all items which should be recommended for each user \n",
    "    \"\"\"\n",
    "    print ('Recommendation: ')\n",
    "    recommended_items = self.recommend(u)[:top]\n",
    "    if self.uuCF:\n",
    "        print ('Top ', top, ' recommend item(s):', recommended_items, 'to user', u)\n",
    "    else: \n",
    "        print ('Top ', top, ' recommend item', u, 'to user(s) : ', recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test function for user 1 forecast movie 1 based on 10 most similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation: \n",
      "Top  10  recommend item(s): [138, 1886, 1430, 641, 823, 3460, 1773, 2661, 231, 663] to user 1\n"
     ]
    }
   ],
   "source": [
    "rs = CF(rate_train, K = 2, uuCF = 1)\n",
    "rs.fit()\n",
    "rs.print_recommendation(u = 1, top = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Evaluate model**\n",
    "\n",
    "Now is the best important part, We will check the error between forecast and actual rating to compare Collaborative Filtering with Content-Based Alogrithms accuracy.\n",
    "\n",
    "**User-user CF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-user CF, RMSE = 0.9937568432929201\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "SE = 0 # squared error\n",
    "users_id_test = np.unique(rate_test[:,0])\n",
    "for n in users_id_test:\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1], normalized = 0)\n",
    "    SE += (pred - rate_test[n, 2])**2 \n",
    "    n_users = len(users_id_test)\n",
    "RMSE = np.sqrt(SE/n_users)\n",
    "print('User-user CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Item-item CF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-item CF, RMSE = 0.9616167529623764\n"
     ]
    }
   ],
   "source": [
    "rs = CF(rate_train, K = 2, uuCF = 0)\n",
    "rs.fit()\n",
    "\n",
    "SE = 0 # squared error\n",
    "items_id_test = np.unique(rate_test[:,0])\n",
    "for n in items_id_test:\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1], normalized = 0)\n",
    "    SE += (pred - rate_test[n, 2])**2 \n",
    "    n_items = len(items_id_test)\n",
    "RMSE = np.sqrt(SE/n_items)\n",
    "print('Item-item CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see, compare with Content-Based Recommendation (error = 1.46) this result is improved a lot. We also tuning model by change K nearest similarity to reduce RMSE. Because of computer's graphic restriction, i will not process tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
